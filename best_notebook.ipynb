{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  #\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1460, 81)\n",
      "Test set size: (1459, 80)\n",
      "START data processing 2019-12-20 15:02:59.615854\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(\"Train set size:\", train.shape)\n",
    "print(\"Test set size:\", test.shape)\n",
    "print('START data processing', datetime.now(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "# Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting outliers\n",
    "train = train[train.GrLivArea < 4500]\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "y = train.SalePrice.reset_index(drop=True)\n",
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "test_features = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 79)\n"
     ]
    }
   ],
   "source": [
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "print(features.shape)\n",
    "# Some of the non-numeric predictors are stored as numbers; we convert them into strings \n",
    "features['MSSubClass'] = features['MSSubClass'].apply(str)\n",
    "features['YrSold'] = features['YrSold'].astype(str)\n",
    "features['MoSold'] = features['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Functional'] = features['Functional'].fillna('Typ')\n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\")\n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\")\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0])\n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.update(features[objects].fillna('None'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in the rest of the NA's\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/stats/stats.py:3538: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n",
      "  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(['Utilities', 'Street', 'PoolQC', ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['YrBltAndRemod'] = features['YearBuilt'] + features['YearRemodAdd']\n",
    "features['TotalSF'] = features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n",
    "                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                              features['WoodDeckSF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified features\n",
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 86)\n",
      "(2917, 333)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "final_features = pd.get_dummies(features).reset_index(drop=True)\n",
    "print(final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_features.iloc[:len(y), :]\n",
    "X_sub = final_features.iloc[len(X):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1458, 333) y (1458,) X_sub (1459, 333)\n"
     ]
    }
   ],
   "source": [
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit = list(overfit)\n",
    "overfit.append('MSZoning_C (all)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(overfit, axis=1).copy()\n",
    "X_sub = X_sub.drop(overfit, axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1453, 331) y (1453,) X_sub (1459, 331)\n"
     ]
    }
   ],
   "source": [
    "print('X', X.shape, 'y', y.shape, 'X_sub', X_sub.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>321</th>\n",
       "      <th>322</th>\n",
       "      <th>323</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "      <td>1.453000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-5.018544e-16</td>\n",
       "      <td>-1.110070e-15</td>\n",
       "      <td>-2.689597e-17</td>\n",
       "      <td>3.679858e-16</td>\n",
       "      <td>1.072171e-15</td>\n",
       "      <td>5.486779e-15</td>\n",
       "      <td>6.357230e-17</td>\n",
       "      <td>2.934106e-17</td>\n",
       "      <td>-3.423124e-17</td>\n",
       "      <td>-6.723994e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.956071e-17</td>\n",
       "      <td>-5.623704e-17</td>\n",
       "      <td>4.890177e-18</td>\n",
       "      <td>7.213011e-17</td>\n",
       "      <td>-1.222544e-18</td>\n",
       "      <td>4.890177e-18</td>\n",
       "      <td>7.335266e-18</td>\n",
       "      <td>-1.467053e-17</td>\n",
       "      <td>-9.780354e-18</td>\n",
       "      <td>5.868213e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "      <td>1.000344e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.773401e+00</td>\n",
       "      <td>-3.483957e+00</td>\n",
       "      <td>-3.710877e+00</td>\n",
       "      <td>-4.568874e+00</td>\n",
       "      <td>-3.291969e+00</td>\n",
       "      <td>-1.689624e+00</td>\n",
       "      <td>-7.439096e-01</td>\n",
       "      <td>-1.149345e+00</td>\n",
       "      <td>-3.503238e-01</td>\n",
       "      <td>-1.852849e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.876256e-02</td>\n",
       "      <td>-2.986727e-01</td>\n",
       "      <td>-4.548588e-02</td>\n",
       "      <td>-2.586084e+00</td>\n",
       "      <td>-2.718636e-01</td>\n",
       "      <td>-5.254069e-02</td>\n",
       "      <td>-9.125541e-02</td>\n",
       "      <td>-1.151071e-01</td>\n",
       "      <td>-2.157243e+00</td>\n",
       "      <td>-3.027547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.213640e-01</td>\n",
       "      <td>-3.716936e-01</td>\n",
       "      <td>-7.983020e-01</td>\n",
       "      <td>-5.153023e-01</td>\n",
       "      <td>-5.726603e-01</td>\n",
       "      <td>-8.657418e-01</td>\n",
       "      <td>-7.439096e-01</td>\n",
       "      <td>-1.149345e+00</td>\n",
       "      <td>-3.503238e-01</td>\n",
       "      <td>-6.851079e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.876256e-02</td>\n",
       "      <td>-2.986727e-01</td>\n",
       "      <td>-4.548588e-02</td>\n",
       "      <td>3.866850e-01</td>\n",
       "      <td>-2.718636e-01</td>\n",
       "      <td>-5.254069e-02</td>\n",
       "      <td>-9.125541e-02</td>\n",
       "      <td>-1.151071e-01</td>\n",
       "      <td>4.635547e-01</td>\n",
       "      <td>-3.027547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.490483e-02</td>\n",
       "      <td>7.129761e-02</td>\n",
       "      <td>-7.015837e-02</td>\n",
       "      <td>-5.153023e-01</td>\n",
       "      <td>5.742351e-02</td>\n",
       "      <td>4.427771e-01</td>\n",
       "      <td>-7.439096e-01</td>\n",
       "      <td>6.245443e-02</td>\n",
       "      <td>-3.503238e-01</td>\n",
       "      <td>-1.731944e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.876256e-02</td>\n",
       "      <td>-2.986727e-01</td>\n",
       "      <td>-4.548588e-02</td>\n",
       "      <td>3.866850e-01</td>\n",
       "      <td>-2.718636e-01</td>\n",
       "      <td>-5.254069e-02</td>\n",
       "      <td>-9.125541e-02</td>\n",
       "      <td>-1.151071e-01</td>\n",
       "      <td>4.635547e-01</td>\n",
       "      <td>-3.027547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.234900e-01</td>\n",
       "      <td>4.693060e-01</td>\n",
       "      <td>6.579853e-01</td>\n",
       "      <td>3.945464e-01</td>\n",
       "      <td>9.528057e-01</td>\n",
       "      <td>9.274138e-01</td>\n",
       "      <td>8.769014e-01</td>\n",
       "      <td>7.365370e-01</td>\n",
       "      <td>-3.503238e-01</td>\n",
       "      <td>6.667620e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.876256e-02</td>\n",
       "      <td>-2.986727e-01</td>\n",
       "      <td>-4.548588e-02</td>\n",
       "      <td>3.866850e-01</td>\n",
       "      <td>-2.718636e-01</td>\n",
       "      <td>-5.254069e-02</td>\n",
       "      <td>-9.125541e-02</td>\n",
       "      <td>-1.151071e-01</td>\n",
       "      <td>4.635547e-01</td>\n",
       "      <td>-3.027547e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.001206e+00</td>\n",
       "      <td>7.088191e+00</td>\n",
       "      <td>2.842416e+00</td>\n",
       "      <td>2.984197e+00</td>\n",
       "      <td>1.284429e+00</td>\n",
       "      <td>1.218196e+00</td>\n",
       "      <td>3.811309e+00</td>\n",
       "      <td>3.036459e+00</td>\n",
       "      <td>4.138631e+00</td>\n",
       "      <td>2.856733e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.701764e+01</td>\n",
       "      <td>3.348146e+00</td>\n",
       "      <td>2.198484e+01</td>\n",
       "      <td>3.866850e-01</td>\n",
       "      <td>3.678315e+00</td>\n",
       "      <td>1.903287e+01</td>\n",
       "      <td>1.095825e+01</td>\n",
       "      <td>8.687559e+00</td>\n",
       "      <td>4.635547e-01</td>\n",
       "      <td>3.303004e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  1.453000e+03  1.453000e+03  1.453000e+03  1.453000e+03  1.453000e+03   \n",
       "mean  -5.018544e-16 -1.110070e-15 -2.689597e-17  3.679858e-16  1.072171e-15   \n",
       "std    1.000344e+00  1.000344e+00  1.000344e+00  1.000344e+00  1.000344e+00   \n",
       "min   -2.773401e+00 -3.483957e+00 -3.710877e+00 -4.568874e+00 -3.291969e+00   \n",
       "25%   -4.213640e-01 -3.716936e-01 -7.983020e-01 -5.153023e-01 -5.726603e-01   \n",
       "50%    6.490483e-02  7.129761e-02 -7.015837e-02 -5.153023e-01  5.742351e-02   \n",
       "75%    5.234900e-01  4.693060e-01  6.579853e-01  3.945464e-01  9.528057e-01   \n",
       "max    8.001206e+00  7.088191e+00  2.842416e+00  2.984197e+00  1.284429e+00   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  1.453000e+03  1.453000e+03  1.453000e+03  1.453000e+03  1.453000e+03   \n",
       "mean   5.486779e-15  6.357230e-17  2.934106e-17 -3.423124e-17 -6.723994e-17   \n",
       "std    1.000344e+00  1.000344e+00  1.000344e+00  1.000344e+00  1.000344e+00   \n",
       "min   -1.689624e+00 -7.439096e-01 -1.149345e+00 -3.503238e-01 -1.852849e+00   \n",
       "25%   -8.657418e-01 -7.439096e-01 -1.149345e+00 -3.503238e-01 -6.851079e-01   \n",
       "50%    4.427771e-01 -7.439096e-01  6.245443e-02 -3.503238e-01 -1.731944e-02   \n",
       "75%    9.274138e-01  8.769014e-01  7.365370e-01 -3.503238e-01  6.667620e-01   \n",
       "max    1.218196e+00  3.811309e+00  3.036459e+00  4.138631e+00  2.856733e+00   \n",
       "\n",
       "       ...           321           322           323           324  \\\n",
       "count  ...  1.453000e+03  1.453000e+03  1.453000e+03  1.453000e+03   \n",
       "mean   ...  1.956071e-17 -5.623704e-17  4.890177e-18  7.213011e-17   \n",
       "std    ...  1.000344e+00  1.000344e+00  1.000344e+00  1.000344e+00   \n",
       "min    ... -5.876256e-02 -2.986727e-01 -4.548588e-02 -2.586084e+00   \n",
       "25%    ... -5.876256e-02 -2.986727e-01 -4.548588e-02  3.866850e-01   \n",
       "50%    ... -5.876256e-02 -2.986727e-01 -4.548588e-02  3.866850e-01   \n",
       "75%    ... -5.876256e-02 -2.986727e-01 -4.548588e-02  3.866850e-01   \n",
       "max    ...  1.701764e+01  3.348146e+00  2.198484e+01  3.866850e-01   \n",
       "\n",
       "                325           326           327           328           329  \\\n",
       "count  1.453000e+03  1.453000e+03  1.453000e+03  1.453000e+03  1.453000e+03   \n",
       "mean  -1.222544e-18  4.890177e-18  7.335266e-18 -1.467053e-17 -9.780354e-18   \n",
       "std    1.000344e+00  1.000344e+00  1.000344e+00  1.000344e+00  1.000344e+00   \n",
       "min   -2.718636e-01 -5.254069e-02 -9.125541e-02 -1.151071e-01 -2.157243e+00   \n",
       "25%   -2.718636e-01 -5.254069e-02 -9.125541e-02 -1.151071e-01  4.635547e-01   \n",
       "50%   -2.718636e-01 -5.254069e-02 -9.125541e-02 -1.151071e-01  4.635547e-01   \n",
       "75%   -2.718636e-01 -5.254069e-02 -9.125541e-02 -1.151071e-01  4.635547e-01   \n",
       "max    3.678315e+00  1.903287e+01  1.095825e+01  8.687559e+00  4.635547e-01   \n",
       "\n",
       "                330  \n",
       "count  1.453000e+03  \n",
       "mean   5.868213e-17  \n",
       "std    1.000344e+00  \n",
       "min   -3.027547e-01  \n",
       "25%   -3.027547e-01  \n",
       "50%   -3.027547e-01  \n",
       "75%   -3.027547e-01  \n",
       "max    3.303004e+00  \n",
       "\n",
       "[8 rows x 331 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "rs = StandardScaler()\n",
    "X_ = rs.fit_transform(X)\n",
    "pd.DataFrame(X_).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>321</th>\n",
       "      <th>322</th>\n",
       "      <th>323</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.051213</td>\n",
       "      <td>-0.058916</td>\n",
       "      <td>-0.012765</td>\n",
       "      <td>-0.025245</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>-0.058202</td>\n",
       "      <td>-0.023029</td>\n",
       "      <td>-0.007131</td>\n",
       "      <td>0.029083</td>\n",
       "      <td>-0.029040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.006227</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>-0.020823</td>\n",
       "      <td>-0.030900</td>\n",
       "      <td>0.052109</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>0.041760</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>-0.006188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008075</td>\n",
       "      <td>0.955867</td>\n",
       "      <td>1.046205</td>\n",
       "      <td>1.010888</td>\n",
       "      <td>1.007805</td>\n",
       "      <td>1.024060</td>\n",
       "      <td>0.998349</td>\n",
       "      <td>1.024249</td>\n",
       "      <td>1.042582</td>\n",
       "      <td>0.999701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773804</td>\n",
       "      <td>0.990779</td>\n",
       "      <td>1.152328</td>\n",
       "      <td>1.022781</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>1.409853</td>\n",
       "      <td>0.998301</td>\n",
       "      <td>1.164978</td>\n",
       "      <td>0.995658</td>\n",
       "      <td>0.990994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.773401</td>\n",
       "      <td>-3.281694</td>\n",
       "      <td>-3.710877</td>\n",
       "      <td>-4.568874</td>\n",
       "      <td>-3.059833</td>\n",
       "      <td>-1.689624</td>\n",
       "      <td>-0.743910</td>\n",
       "      <td>-1.149345</td>\n",
       "      <td>-0.350324</td>\n",
       "      <td>-1.852849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058763</td>\n",
       "      <td>-0.298673</td>\n",
       "      <td>-0.045486</td>\n",
       "      <td>-2.586084</td>\n",
       "      <td>-0.271864</td>\n",
       "      <td>-0.052541</td>\n",
       "      <td>-0.091255</td>\n",
       "      <td>-0.115107</td>\n",
       "      <td>-2.157243</td>\n",
       "      <td>-0.302755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.421364</td>\n",
       "      <td>-0.408563</td>\n",
       "      <td>-0.798302</td>\n",
       "      <td>-0.515302</td>\n",
       "      <td>-0.605823</td>\n",
       "      <td>-1.059597</td>\n",
       "      <td>-0.743910</td>\n",
       "      <td>-1.149345</td>\n",
       "      <td>-0.350324</td>\n",
       "      <td>-0.697809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058763</td>\n",
       "      <td>-0.298673</td>\n",
       "      <td>-0.045486</td>\n",
       "      <td>0.386685</td>\n",
       "      <td>-0.271864</td>\n",
       "      <td>-0.052541</td>\n",
       "      <td>-0.091255</td>\n",
       "      <td>-0.115107</td>\n",
       "      <td>0.463555</td>\n",
       "      <td>-0.302755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.064905</td>\n",
       "      <td>0.055175</td>\n",
       "      <td>-0.070158</td>\n",
       "      <td>-0.515302</td>\n",
       "      <td>0.057424</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>-0.743910</td>\n",
       "      <td>-0.013169</td>\n",
       "      <td>-0.350324</td>\n",
       "      <td>-0.049835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058763</td>\n",
       "      <td>-0.298673</td>\n",
       "      <td>-0.045486</td>\n",
       "      <td>0.386685</td>\n",
       "      <td>-0.271864</td>\n",
       "      <td>-0.052541</td>\n",
       "      <td>-0.091255</td>\n",
       "      <td>-0.115107</td>\n",
       "      <td>0.463555</td>\n",
       "      <td>-0.302755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.523490</td>\n",
       "      <td>0.455131</td>\n",
       "      <td>0.657985</td>\n",
       "      <td>0.394546</td>\n",
       "      <td>0.985968</td>\n",
       "      <td>0.927414</td>\n",
       "      <td>0.872200</td>\n",
       "      <td>0.811355</td>\n",
       "      <td>-0.350324</td>\n",
       "      <td>0.647325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058763</td>\n",
       "      <td>-0.298673</td>\n",
       "      <td>-0.045486</td>\n",
       "      <td>0.386685</td>\n",
       "      <td>-0.271864</td>\n",
       "      <td>-0.052541</td>\n",
       "      <td>-0.091255</td>\n",
       "      <td>-0.115107</td>\n",
       "      <td>0.463555</td>\n",
       "      <td>-0.302755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.862692</td>\n",
       "      <td>3.849003</td>\n",
       "      <td>2.842416</td>\n",
       "      <td>2.984197</td>\n",
       "      <td>1.284429</td>\n",
       "      <td>1.218196</td>\n",
       "      <td>3.400013</td>\n",
       "      <td>5.279539</td>\n",
       "      <td>4.175619</td>\n",
       "      <td>2.620588</td>\n",
       "      <td>...</td>\n",
       "      <td>17.017638</td>\n",
       "      <td>3.348146</td>\n",
       "      <td>21.984843</td>\n",
       "      <td>0.386685</td>\n",
       "      <td>3.678315</td>\n",
       "      <td>19.032866</td>\n",
       "      <td>10.958254</td>\n",
       "      <td>8.687559</td>\n",
       "      <td>0.463555</td>\n",
       "      <td>3.303004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1            2            3            4    \\\n",
       "count  1459.000000  1459.000000  1459.000000  1459.000000  1459.000000   \n",
       "mean     -0.051213    -0.058916    -0.012765    -0.025245     0.002964   \n",
       "std       1.008075     0.955867     1.046205     1.010888     1.007805   \n",
       "min      -2.773401    -3.281694    -3.710877    -4.568874    -3.059833   \n",
       "25%      -0.421364    -0.408563    -0.798302    -0.515302    -0.605823   \n",
       "50%       0.064905     0.055175    -0.070158    -0.515302     0.057424   \n",
       "75%       0.523490     0.455131     0.657985     0.394546     0.985968   \n",
       "max       4.862692     3.849003     2.842416     2.984197     1.284429   \n",
       "\n",
       "               5            6            7            8            9    ...  \\\n",
       "count  1459.000000  1459.000000  1459.000000  1459.000000  1459.000000  ...   \n",
       "mean     -0.058202    -0.023029    -0.007131     0.029083    -0.029040  ...   \n",
       "std       1.024060     0.998349     1.024249     1.042582     0.999701  ...   \n",
       "min      -1.689624    -0.743910    -1.149345    -0.350324    -1.852849  ...   \n",
       "25%      -1.059597    -0.743910    -1.149345    -0.350324    -0.697809  ...   \n",
       "50%       0.345850    -0.743910    -0.013169    -0.350324    -0.049835  ...   \n",
       "75%       0.927414     0.872200     0.811355    -0.350324     0.647325  ...   \n",
       "max       1.218196     3.400013     5.279539     4.175619     2.620588  ...   \n",
       "\n",
       "               321          322          323          324          325  \\\n",
       "count  1459.000000  1459.000000  1459.000000  1459.000000  1459.000000   \n",
       "mean     -0.023650    -0.006227     0.014913    -0.020823    -0.030900   \n",
       "std       0.773804     0.990779     1.152328     1.022781     0.945727   \n",
       "min      -0.058763    -0.298673    -0.045486    -2.586084    -0.271864   \n",
       "25%      -0.058763    -0.298673    -0.045486     0.386685    -0.271864   \n",
       "50%      -0.058763    -0.298673    -0.045486     0.386685    -0.271864   \n",
       "75%      -0.058763    -0.298673    -0.045486     0.386685    -0.271864   \n",
       "max      17.017638     3.348146    21.984843     0.386685     3.678315   \n",
       "\n",
       "               326          327          328          329          330  \n",
       "count  1459.000000  1459.000000  1459.000000  1459.000000  1459.000000  \n",
       "mean      0.052109    -0.000375     0.041760     0.005499    -0.006188  \n",
       "std       1.409853     0.998301     1.164978     0.995658     0.990994  \n",
       "min      -0.052541    -0.091255    -0.115107    -2.157243    -0.302755  \n",
       "25%      -0.052541    -0.091255    -0.115107     0.463555    -0.302755  \n",
       "50%      -0.052541    -0.091255    -0.115107     0.463555    -0.302755  \n",
       "75%      -0.052541    -0.091255    -0.115107     0.463555    -0.302755  \n",
       "max      19.032866    10.958254     8.687559     0.463555     3.303004  \n",
       "\n",
       "[8 rows x 331 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub_ = rs.transform(X_sub)\n",
    "pd.DataFrame(X_sub_).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(X_, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train=train, y_train=y_train, test=test, y_test=y_test, \n",
    "                batch_size=128, epochs=1001, patience=1000, \n",
    "                nlayers=1, nneurals=64):\n",
    "    start = datetime.now()\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(nneurals, activation='relu', input_shape=[train.shape[1]]),\n",
    "\n",
    "    ])\n",
    "    for i in range(nlayers-1):\n",
    "        model.add(layers.Dense(nneurals, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(loss='mae',\n",
    "                optimizer=optimizer)\n",
    "    history = model.fit(pd.DataFrame(train), y_train, \n",
    "                        epochs=epochs, batch_size=batch_size,\n",
    "                        validation_split=0.1, verbose=0, \n",
    "                        callbacks=[tfdocs.modeling.EpochDots(), \n",
    "                                   tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)])\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    print(hist.tail())\n",
    "    model.evaluate(pd.DataFrame(test), y_test)\n",
    "    print('time=', datetime.now() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlayers= 8 nneurals= 256\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "..................................................\n",
      "Epoch: 100, loss:0.5115,  val_loss:0.6215,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.3067,  val_loss:0.4275,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.1152,  val_loss:0.2607,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.1149,  val_loss:0.2146,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.1098,  val_loss:0.1095,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.0761,  val_loss:0.1446,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.0327,  val_loss:0.0905,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.1187,  val_loss:0.1160,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.0294,  val_loss:0.0754,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.1024,  val_loss:0.1556,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.107569  0.113001    996\n",
      "997   0.108145  0.142527    997\n",
      "998   0.104935  0.129255    998\n",
      "999   0.101951  0.129543    999\n",
      "1000  0.102370  0.155563   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 54us/sample - loss: 0.1695\n",
      "time= 0:00:37.024122\n",
      "nlayers= 8 nneurals= 512\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:6.6490,  val_loss:5.6756,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.2695,  val_loss:0.2808,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.0834,  val_loss:0.2466,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.1830,  val_loss:0.2432,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.0808,  val_loss:0.0739,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.1400,  val_loss:0.1434,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.0678,  val_loss:0.1135,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.0273,  val_loss:0.0687,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.0441,  val_loss:0.0689,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.0609,  val_loss:0.0887,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.0544,  val_loss:0.1134,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.027586  0.081358    996\n",
      "997   0.049146  0.074597    997\n",
      "998   0.060399  0.101639    998\n",
      "999   0.058349  0.078334    999\n",
      "1000  0.054414  0.113389   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 53us/sample - loss: 0.1254\n",
      "time= 0:00:31.210577\n",
      "nlayers= 8 nneurals= 1024\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "..............................................................................\n",
      "Epoch: 300, loss:0.0999,  val_loss:0.0895,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.0430,  val_loss:0.0703,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.0360,  val_loss:0.1252,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.0400,  val_loss:0.0705,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.0403,  val_loss:0.0854,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.1484,  val_loss:0.1627,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.0521,  val_loss:0.0853,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.0789,  val_loss:0.0938,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.059745  0.095355    996\n",
      "997   0.069489  0.077414    997\n",
      "998   0.046875  0.152292    998\n",
      "999   0.100695  0.136195    999\n",
      "1000  0.078908  0.093808   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 55us/sample - loss: 0.1211\n",
      "time= 0:00:36.156871\n",
      "nlayers= 16 nneurals= 256\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:8.3104,  val_loss:3.7077,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.3706,  val_loss:0.3114,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.0736,  val_loss:0.1087,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.1045,  val_loss:0.1532,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.1029,  val_loss:0.1852,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.0496,  val_loss:0.1326,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.1419,  val_loss:0.0794,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.0730,  val_loss:0.0971,  \n",
      ".................................................................................................\n",
      "Epoch: 1000, loss:0.0638,  val_loss:0.0989,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.088358  0.078581    996\n",
      "997   0.055099  0.085837    997\n",
      "998   0.031264  0.076803    998\n",
      "999   0.059988  0.125014    999\n",
      "1000  0.063818  0.098884   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 58us/sample - loss: 0.1079\n",
      "time= 0:00:40.840336\n",
      "nlayers= 16 nneurals= 512\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:8.6806,  val_loss:2.5644,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.0776,  val_loss:0.1117,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.1239,  val_loss:0.0900,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.1680,  val_loss:0.1975,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.3186,  val_loss:0.3681,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.0461,  val_loss:0.0902,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.0775,  val_loss:0.0901,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.0607,  val_loss:0.0806,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.0746,  val_loss:0.0970,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.0590,  val_loss:0.1208,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.0649,  val_loss:0.0870,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.055156  0.100851    996\n",
      "997   0.073765  0.087321    997\n",
      "998   0.061900  0.088942    998\n",
      "999   0.066385  0.106818    999\n",
      "1000  0.064868  0.086957   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 60us/sample - loss: 0.0915\n",
      "time= 0:00:42.708185\n",
      "nlayers= 16 nneurals= 1024\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:15.3983,  val_loss:8.9422,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.5380,  val_loss:0.6290,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.0617,  val_loss:0.0725,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.0569,  val_loss:0.0799,  \n",
      "................................................\n",
      "Epoch: 500, loss:0.0833,  val_loss:0.1188,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.0420,  val_loss:0.0924,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.1431,  val_loss:0.1621,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.0723,  val_loss:0.0845,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.0285,  val_loss:0.0926,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.0348,  val_loss:0.1019,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.039571  0.077809    996\n",
      "997   0.072138  0.105125    997\n",
      "998   0.071487  0.096460    998\n",
      "999   0.058837  0.080381    999\n",
      "1000  0.034845  0.101858   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 61us/sample - loss: 0.1045\n",
      "time= 0:00:53.406117\n",
      "nlayers= 32 nneurals= 256\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:11.3619,  val_loss:2.9634,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.1901,  val_loss:0.1115,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.0741,  val_loss:0.1161,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.1294,  val_loss:0.1031,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.1073,  val_loss:0.1040,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.0956,  val_loss:0.0886,  \n",
      "................................................................\n",
      "Epoch: 700, loss:0.0830,  val_loss:0.1101,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.0671,  val_loss:0.1026,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.0413,  val_loss:0.0785,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.0626,  val_loss:0.1002,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.063179  0.106856    996\n",
      "997   0.064293  0.102487    997\n",
      "998   0.061467  0.103355    998\n",
      "999   0.062915  0.114123    999\n",
      "1000  0.062626  0.100230   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 87us/sample - loss: 0.1159\n",
      "time= 0:01:00.470036\n",
      "nlayers= 32 nneurals= 512\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:12.3965,  val_loss:11.7525,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.2525,  val_loss:0.1022,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.1326,  val_loss:0.2040,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.0860,  val_loss:0.0740,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.1963,  val_loss:0.2779,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.0686,  val_loss:0.0940,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.0396,  val_loss:0.0834,  \n",
      "........................................................................\n",
      "Epoch: 700, loss:0.0675,  val_loss:0.1088,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.0387,  val_loss:0.0882,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.0668,  val_loss:0.0895,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.0700,  val_loss:0.1111,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.057700  0.086366    996\n",
      "997   0.032075  0.085237    997\n",
      "998   0.061972  0.148358    998\n",
      "999   0.117520  0.135945    999\n",
      "1000  0.069956  0.111118   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 82us/sample - loss: 0.1056\n",
      "time= 0:01:02.373777\n",
      "nlayers= 32 nneurals= 1024\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:12.7909,  val_loss:11.8309,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.3208,  val_loss:0.3142,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.3456,  val_loss:0.4265,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.3126,  val_loss:0.3214,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.3888,  val_loss:0.3443,  \n",
      ".........................................................................\n",
      "Epoch: 500, loss:0.3100,  val_loss:0.3306,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.3121,  val_loss:0.3209,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.3093,  val_loss:0.3278,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.3068,  val_loss:0.3460,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.3049,  val_loss:0.3240,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.3200,  val_loss:0.3878,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.304879  0.321625    996\n",
      "997   0.314269  0.331065    997\n",
      "998   0.310488  0.315959    998\n",
      "999   0.313609  0.353610    999\n",
      "1000  0.320018  0.387773   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 80us/sample - loss: 0.4043\n",
      "time= 0:01:29.905351\n",
      "nlayers= 64 nneurals= 256\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:11.4604,  val_loss:5.1486,  \n",
      "...............................................................................\n",
      "Epoch: 100, loss:0.3112,  val_loss:0.3200,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.3199,  val_loss:0.3267,  \n",
      "....................................................................................................\n",
      "Epoch: 300, loss:0.3283,  val_loss:0.3133,  \n",
      "....................................................................................................\n",
      "Epoch: 400, loss:0.3212,  val_loss:0.3134,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.3327,  val_loss:0.3456,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.3097,  val_loss:0.3235,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.3085,  val_loss:0.3193,  \n",
      "...............................................................................\n",
      "Epoch: 800, loss:0.3080,  val_loss:0.3375,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.3221,  val_loss:0.3203,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, loss:0.3102,  val_loss:0.3136,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.334400  0.321951    996\n",
      "997   0.311588  0.319464    997\n",
      "998   0.310096  0.321962    998\n",
      "999   0.310865  0.341193    999\n",
      "1000  0.310248  0.313570   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 127us/sample - loss: 0.3384\n",
      "time= 0:01:41.571049\n",
      "nlayers= 64 nneurals= 512\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:21.4168,  val_loss:10.2395,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.3329,  val_loss:0.3144,  \n",
      "....................................................................................................\n",
      "Epoch: 200, loss:0.3141,  val_loss:0.3683,  \n",
      ".....................................................................................................................................................................................\n",
      "Epoch: 400, loss:0.3147,  val_loss:0.3413,  \n",
      "....................................................................................................\n",
      "Epoch: 500, loss:0.3152,  val_loss:0.3164,  \n",
      "....................................................................................................\n",
      "Epoch: 600, loss:0.3064,  val_loss:0.3399,  \n",
      "....................................................................................................\n",
      "Epoch: 700, loss:0.3160,  val_loss:0.3229,  \n",
      "....................................................................................................\n",
      "Epoch: 800, loss:0.3244,  val_loss:0.3350,  \n",
      "....................................................................................................\n",
      "Epoch: 900, loss:0.3357,  val_loss:0.3196,  \n",
      "..................................................................................\n",
      "Epoch: 1000, loss:0.3177,  val_loss:0.3151,  \n",
      ".          loss  val_loss  epoch\n",
      "996   0.316990  0.345290    996\n",
      "997   0.338411  0.368370    997\n",
      "998   0.327606  0.313642    998\n",
      "999   0.310828  0.326321    999\n",
      "1000  0.317749  0.315136   1000\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "146/146 [==============================] - 0s 119us/sample - loss: 0.3375\n",
      "time= 0:01:45.608389\n",
      "nlayers= 64 nneurals= 1024\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "\n",
      "Epoch: 0, loss:45.5593,  val_loss:11.7746,  \n",
      "....................................................................................................\n",
      "Epoch: 100, loss:0.3111,  val_loss:0.3152,  \n",
      "......................................................"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-255854294bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnneurals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nlayers='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nneurals='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnneurals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnneurals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnneurals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-e5b4917f9087>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(train, y_train, test, y_test, batch_size, epochs, patience, nlayers, nneurals)\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         callbacks=[tfdocs.modeling.EpochDots(), \n\u001b[0;32m---> 21\u001b[0;31m                                    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)])\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3746\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3748\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3749\u001b[0m         expand_composites=True)\n\u001b[1;32m   3750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3746\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3748\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3749\u001b[0m         expand_composites=True)\n\u001b[1;32m   3750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "for nlayers in [8, 16, 32, 64, 128]:\n",
    "    for nneurals in [256, 512, 1024]:\n",
    "        print('nlayers=', nlayers, 'nneurals=', nneurals)\n",
    "        model = build_model(nlayers=nlayers, nneurals=nneurals)\n",
    "print('total time: ', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "nlayers, nneurals = 16, 512\n",
    "print('nlayers=', nlayers, 'nneurals=', nneurals)\n",
    "model = build_model(train=X_, y_train=y, nlayers=nlayers, nneurals=nneurals)\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "submission.iloc[:, 1] = np.floor(np.expm1(model.predict(pd.DataFrame(X_sub_))))\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print('submission time:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c home-data-for-ml-course -f submission.csv -m 'a submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
